{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "      <th>error type</th>\n",
       "      <th>netlist component</th>\n",
       "      <th>suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fatal error: DC Transfer Function: Voltage sou...</td>\n",
       "      <td>Invalid DC analysis statement</td>\n",
       "      <td>DC analysis</td>\n",
       "      <td>Go to KiCadToNgSpice Conversion. Verify that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fatal error: DC Transfer Function: Voltage sou...</td>\n",
       "      <td>Invalid DC analysis statement</td>\n",
       "      <td>DC analysis</td>\n",
       "      <td>Go to KiCadToNgSpice Conversion. Verify that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fatal error: DC Transfer Function: Voltage sou...</td>\n",
       "      <td>Invalid DC analysis statement</td>\n",
       "      <td>DC analysis</td>\n",
       "      <td>Go to KiCadToNgSpice Conversion. Verify that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fatal error: DC Transfer Function: Voltage sou...</td>\n",
       "      <td>Invalid DC analysis statement</td>\n",
       "      <td>DC analysis</td>\n",
       "      <td>Go to KiCadToNgSpice Conversion. Verify that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fatal error: DC Transfer Function: Voltage sou...</td>\n",
       "      <td>Invalid DC analysis statement</td>\n",
       "      <td>DC analysis</td>\n",
       "      <td>Go to KiCadToNgSpice Conversion. Verify that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>Fatal error: instance v45 is a shorted VSRC\\nd...</td>\n",
       "      <td>Shorted Voltage Source</td>\n",
       "      <td>Voltage Source</td>\n",
       "      <td>Review the schematic and verify the connection...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>Fatal error: instance v59 is a shorted VSRC\\nd...</td>\n",
       "      <td>Shorted Voltage Source</td>\n",
       "      <td>Voltage Source</td>\n",
       "      <td>Review the schematic and verify the connection...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>Fatal error: instance v82 is a shorted VSRC\\nd...</td>\n",
       "      <td>Shorted Voltage Source</td>\n",
       "      <td>Voltage Source</td>\n",
       "      <td>Review the schematic and verify the connection...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>Fatal error: instance v7 is a shorted VSRC\\ndo...</td>\n",
       "      <td>Shorted Voltage Source</td>\n",
       "      <td>Voltage Source</td>\n",
       "      <td>Review the schematic and verify the connection...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>Fatal error: instance v20 is a shorted VSRC\\nd...</td>\n",
       "      <td>Shorted Voltage Source</td>\n",
       "      <td>Voltage Source</td>\n",
       "      <td>Review the schematic and verify the connection...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>877 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 error  \\\n",
       "0    Fatal error: DC Transfer Function: Voltage sou...   \n",
       "1    Fatal error: DC Transfer Function: Voltage sou...   \n",
       "2    Fatal error: DC Transfer Function: Voltage sou...   \n",
       "3    Fatal error: DC Transfer Function: Voltage sou...   \n",
       "4    Fatal error: DC Transfer Function: Voltage sou...   \n",
       "..                                                 ...   \n",
       "872  Fatal error: instance v45 is a shorted VSRC\\nd...   \n",
       "873  Fatal error: instance v59 is a shorted VSRC\\nd...   \n",
       "874  Fatal error: instance v82 is a shorted VSRC\\nd...   \n",
       "875  Fatal error: instance v7 is a shorted VSRC\\ndo...   \n",
       "876  Fatal error: instance v20 is a shorted VSRC\\nd...   \n",
       "\n",
       "                        error type netlist component  \\\n",
       "0    Invalid DC analysis statement       DC analysis   \n",
       "1    Invalid DC analysis statement       DC analysis   \n",
       "2    Invalid DC analysis statement       DC analysis   \n",
       "3    Invalid DC analysis statement       DC analysis   \n",
       "4    Invalid DC analysis statement       DC analysis   \n",
       "..                             ...               ...   \n",
       "872         Shorted Voltage Source    Voltage Source   \n",
       "873         Shorted Voltage Source    Voltage Source   \n",
       "874         Shorted Voltage Source    Voltage Source   \n",
       "875         Shorted Voltage Source    Voltage Source   \n",
       "876         Shorted Voltage Source    Voltage Source   \n",
       "\n",
       "                                            suggestion  \n",
       "0    Go to KiCadToNgSpice Conversion. Verify that t...  \n",
       "1    Go to KiCadToNgSpice Conversion. Verify that t...  \n",
       "2    Go to KiCadToNgSpice Conversion. Verify that t...  \n",
       "3    Go to KiCadToNgSpice Conversion. Verify that t...  \n",
       "4    Go to KiCadToNgSpice Conversion. Verify that t...  \n",
       "..                                                 ...  \n",
       "872  Review the schematic and verify the connection...  \n",
       "873  Review the schematic and verify the connection...  \n",
       "874  Review the schematic and verify the connection...  \n",
       "875  Review the schematic and verify the connection...  \n",
       "876  Review the schematic and verify the connection...  \n",
       "\n",
       "[877 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON file\n",
    "with open('merged_error_logs.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert the JSON data into a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['error'])\n",
    "X = tokenizer.texts_to_sequences(df['error'])\n",
    "\n",
    "# Padding sequences to ensure uniform length\n",
    "max_sequence_length = max([len(seq) for seq in X])  # Or set it to a fixed value, like 100 or 200\n",
    "X_pad = pad_sequences(X, maxlen=max_sequence_length)\n",
    "\n",
    "# Label Encoding (Error types)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['error type'])\n",
    "label_map = {label: idx for idx, label in enumerate(df[\"error type\"].unique())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Control Card Error ': 0, 'Invalid DC analysis statement': 1, 'Invalid component parameter or syntax error': 2, 'Invalid parameter in transient statement': 3, 'Invalid start time in transient statement': 4, 'Invalid step time in transient statement': 5, 'Invalid stop time in transient statement': 6, 'Missing Model Definition': 7, 'Model Type Mismatch': 8, 'Short circuit error': 9, 'Shorted Voltage Source': 10, 'Unknown Subcircuit Error': 11}\n"
     ]
    }
   ],
   "source": [
    "# Get the mapping of labels to encoded values\n",
    "label_map = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "# Print the label mapping\n",
    "print(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 340, 64)           37312     \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 340, 128)          98816     \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 12)                204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 188348 (735.73 KB)\n",
      "Trainable params: 188348 (735.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(12, activation=\"softmax\")  # Multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "22/22 [==============================] - 11s 419ms/step - loss: 2.2989 - accuracy: 0.3324 - val_loss: 2.0384 - val_accuracy: 0.3239\n",
      "Epoch 2/80\n",
      "22/22 [==============================] - 8s 388ms/step - loss: 1.8218 - accuracy: 0.3837 - val_loss: 1.6059 - val_accuracy: 0.4148\n",
      "Epoch 3/80\n",
      "22/22 [==============================] - 9s 406ms/step - loss: 1.2858 - accuracy: 0.5150 - val_loss: 1.2601 - val_accuracy: 0.6136\n",
      "Epoch 4/80\n",
      "22/22 [==============================] - 8s 370ms/step - loss: 1.0096 - accuracy: 0.6748 - val_loss: 1.0190 - val_accuracy: 0.6761\n",
      "Epoch 5/80\n",
      "22/22 [==============================] - 8s 380ms/step - loss: 0.7220 - accuracy: 0.7817 - val_loss: 0.7554 - val_accuracy: 0.8352\n",
      "Epoch 6/80\n",
      "22/22 [==============================] - 8s 362ms/step - loss: 0.5330 - accuracy: 0.8673 - val_loss: 0.5864 - val_accuracy: 0.8580\n",
      "Epoch 7/80\n",
      "22/22 [==============================] - 8s 369ms/step - loss: 0.3996 - accuracy: 0.8845 - val_loss: 0.4303 - val_accuracy: 0.8807\n",
      "Epoch 8/80\n",
      "22/22 [==============================] - 9s 407ms/step - loss: 0.2815 - accuracy: 0.9201 - val_loss: 0.3123 - val_accuracy: 0.8977\n",
      "Epoch 9/80\n",
      "22/22 [==============================] - 8s 374ms/step - loss: 0.1975 - accuracy: 0.9515 - val_loss: 0.2152 - val_accuracy: 0.9489\n",
      "Epoch 10/80\n",
      "22/22 [==============================] - 9s 401ms/step - loss: 0.1171 - accuracy: 0.9815 - val_loss: 0.1257 - val_accuracy: 0.9489\n",
      "Epoch 11/80\n",
      "22/22 [==============================] - 9s 398ms/step - loss: 0.0739 - accuracy: 0.9843 - val_loss: 0.0803 - val_accuracy: 0.9773\n",
      "Epoch 12/80\n",
      "22/22 [==============================] - 9s 391ms/step - loss: 0.0498 - accuracy: 0.9929 - val_loss: 1.5928 - val_accuracy: 0.7784\n",
      "Epoch 13/80\n",
      "22/22 [==============================] - 8s 364ms/step - loss: 0.5028 - accuracy: 0.8502 - val_loss: 0.3129 - val_accuracy: 0.9489\n",
      "Epoch 14/80\n",
      "22/22 [==============================] - 9s 426ms/step - loss: 0.1432 - accuracy: 0.9815 - val_loss: 0.1876 - val_accuracy: 0.9489\n",
      "Epoch 15/80\n",
      "22/22 [==============================] - 8s 349ms/step - loss: 0.0945 - accuracy: 0.9815 - val_loss: 0.1526 - val_accuracy: 0.9489\n",
      "Epoch 16/80\n",
      "22/22 [==============================] - 7s 338ms/step - loss: 0.0713 - accuracy: 0.9815 - val_loss: 0.1178 - val_accuracy: 0.9489\n",
      "Epoch 17/80\n",
      "22/22 [==============================] - 8s 369ms/step - loss: 0.0582 - accuracy: 0.9815 - val_loss: 0.1034 - val_accuracy: 0.9489\n",
      "Epoch 18/80\n",
      "22/22 [==============================] - 7s 333ms/step - loss: 0.0500 - accuracy: 0.9815 - val_loss: 0.0874 - val_accuracy: 0.9489\n",
      "Epoch 19/80\n",
      "22/22 [==============================] - 8s 365ms/step - loss: 0.0431 - accuracy: 0.9815 - val_loss: 0.0733 - val_accuracy: 0.9489\n",
      "Epoch 20/80\n",
      "22/22 [==============================] - 8s 355ms/step - loss: 0.0374 - accuracy: 0.9914 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "22/22 [==============================] - 9s 392ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "22/22 [==============================] - 8s 378ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "22/22 [==============================] - 8s 357ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "22/22 [==============================] - 10s 473ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "22/22 [==============================] - 9s 424ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "22/22 [==============================] - 9s 388ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "22/22 [==============================] - 8s 363ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "22/22 [==============================] - 8s 352ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "22/22 [==============================] - 8s 363ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "22/22 [==============================] - 8s 391ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "22/22 [==============================] - 8s 344ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "22/22 [==============================] - 8s 381ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "22/22 [==============================] - 8s 386ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "22/22 [==============================] - 8s 367ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "22/22 [==============================] - 8s 350ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "22/22 [==============================] - 8s 372ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "22/22 [==============================] - 8s 353ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "22/22 [==============================] - 7s 306ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "22/22 [==============================] - 8s 372ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "22/22 [==============================] - 8s 372ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "22/22 [==============================] - 7s 338ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "22/22 [==============================] - 8s 368ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "22/22 [==============================] - 8s 355ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "22/22 [==============================] - 9s 402ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "22/22 [==============================] - 8s 358ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "22/22 [==============================] - 8s 340ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "22/22 [==============================] - 8s 360ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "22/22 [==============================] - 8s 357ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "22/22 [==============================] - 7s 316ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "22/22 [==============================] - 7s 340ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "22/22 [==============================] - 7s 313ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "22/22 [==============================] - 8s 354ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "22/22 [==============================] - 8s 351ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "22/22 [==============================] - 8s 358ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "22/22 [==============================] - 8s 356ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9489\n",
      "Epoch 56/80\n",
      "22/22 [==============================] - 8s 389ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "22/22 [==============================] - 8s 369ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "22/22 [==============================] - 8s 345ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "22/22 [==============================] - 8s 347ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "22/22 [==============================] - 8s 362ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "22/22 [==============================] - 8s 377ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "22/22 [==============================] - 8s 340ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "22/22 [==============================] - 10s 439ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "22/22 [==============================] - 8s 358ms/step - loss: 9.9121e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "22/22 [==============================] - 7s 332ms/step - loss: 9.2724e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "22/22 [==============================] - 7s 311ms/step - loss: 8.8132e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "22/22 [==============================] - 7s 315ms/step - loss: 8.4083e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "22/22 [==============================] - 7s 323ms/step - loss: 7.9683e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "22/22 [==============================] - 7s 314ms/step - loss: 7.5952e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "22/22 [==============================] - 7s 326ms/step - loss: 7.2503e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "22/22 [==============================] - 8s 386ms/step - loss: 6.9421e-04 - accuracy: 1.0000 - val_loss: 9.7175e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "22/22 [==============================] - 7s 339ms/step - loss: 6.6721e-04 - accuracy: 1.0000 - val_loss: 9.1906e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "22/22 [==============================] - 8s 351ms/step - loss: 6.4190e-04 - accuracy: 1.0000 - val_loss: 8.9246e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "22/22 [==============================] - 7s 314ms/step - loss: 6.2076e-04 - accuracy: 1.0000 - val_loss: 8.3970e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "22/22 [==============================] - 7s 332ms/step - loss: 5.9258e-04 - accuracy: 1.0000 - val_loss: 8.0773e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "22/22 [==============================] - 8s 368ms/step - loss: 5.7134e-04 - accuracy: 1.0000 - val_loss: 7.8344e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "22/22 [==============================] - 8s 351ms/step - loss: 5.4724e-04 - accuracy: 1.0000 - val_loss: 7.5370e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "22/22 [==============================] - 8s 358ms/step - loss: 5.2889e-04 - accuracy: 1.0000 - val_loss: 7.2591e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "22/22 [==============================] - 8s 364ms/step - loss: 5.0943e-04 - accuracy: 1.0000 - val_loss: 6.9747e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "22/22 [==============================] - 8s 364ms/step - loss: 4.9269e-04 - accuracy: 1.0000 - val_loss: 6.7885e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f4664473af0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the LSTM model\n",
    "model.fit(X_train, y_train, epochs=80, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 416ms/step\n",
      "Model Type Mismatch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def classify_ngspice_error(error_message):\n",
    "    seq = tokenizer.texts_to_sequences([error_message])\n",
    "    padded_seq = pad_sequences(seq, maxlen=max_sequence_length)\n",
    "    prediction = model.predict(padded_seq)\n",
    "    predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
    "    return predicted_label[0]\n",
    "\n",
    "# Example usage\n",
    "print(classify_ngspice_error(\"incorect model type\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 dict_keys(['Control Card Error ', 'Invalid DC analysis statement', 'Invalid component parameter or syntax error', 'Invalid parameter in transient statement', 'Invalid start time in transient statement', 'Invalid step time in transient statement', 'Invalid stop time in transient statement', 'Missing Model Definition', 'Model Type Mismatch', 'Short circuit error', 'Shorted Voltage Source', 'Unknown Subcircuit Error'])\n"
     ]
    }
   ],
   "source": [
    "print(len(label_map.keys()), label_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/myo/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model\n",
    "model.save(\"ngspice_error_classifier.h5\")\n",
    "import pickle\n",
    "\n",
    "# Save the entire model\n",
    "model.save(\"ngspice_error_classifier.h5\")\n",
    "import pickle\n",
    "\n",
    "metadata = {\n",
    "    'max_length': max_sequence_length,\n",
    "    'tokenizer': tokenizer,\n",
    "    'label_encoder': label_encoder\n",
    "}\n",
    "\n",
    "with open('metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you already have a DataFrame 'df' with 'error type', 'netlist component', and 'suggestion'\n",
    "\n",
    "# Step 1: Encode the features\n",
    "error_type_encoder = LabelEncoder()\n",
    "netlist_component_encoder = LabelEncoder()\n",
    "\n",
    "df.loc[:, 'error_type_encoded'] = error_type_encoder.fit_transform(df['error type'])\n",
    "df.loc[:, 'netlist_component_encoded'] = netlist_component_encoder.fit_transform(df['netlist component'])\n",
    "\n",
    "# Step 2: Encode the target variable (suggestion)\n",
    "suggestion_encoder = LabelEncoder()\n",
    "df.loc[:, 'suggestion_encoded'] = suggestion_encoder.fit_transform(df['suggestion'])\n",
    "\n",
    "# Step 3: Prepare the features (X) and target (y)\n",
    "X = df[['error_type_encoded', 'netlist_component_encoded']]  # Features\n",
    "y = df['suggestion_encoded']  # Target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # Using 100 trees\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_columns.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(rf_model, \"random_forest_model.pkl\")  # Save the trained model\n",
    "joblib.dump(error_type_encoder, \"error_type_encoder.pkl\")  # Save encoders\n",
    "joblib.dump(netlist_component_encoder, \"netlist_component_encoder.pkl\")\n",
    "joblib.dump(suggestion_encoder, \"suggestion_encoder.pkl\")\n",
    "joblib.dump(X.columns.tolist(), \"feature_columns.pkl\")  # Save feature names\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
